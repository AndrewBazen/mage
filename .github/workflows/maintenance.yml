name: Maintenance

on:
  schedule:
    # Run every Monday at 09:00 UTC
    - cron: '0 9 * * 1'
  workflow_dispatch:
    inputs:
      update_dependencies:
        description: 'Update dependencies'
        type: boolean
        default: true
      security_audit:
        description: 'Run security audit'
        type: boolean
        default: true
      performance_check:
        description: 'Run performance checks'
        type: boolean
        default: false

env:
  CARGO_TERM_COLOR: always

jobs:
  dependency-updates:
    name: Update Dependencies
    if: github.event_name == 'schedule' || github.event.inputs.update_dependencies == 'true'
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
    
    - name: Install Rust
      uses: dtolnay/rust-toolchain@stable
    
    - name: Install cargo-edit
      run: cargo install cargo-edit
    
    - name: Install cargo-outdated
      run: cargo install cargo-outdated
    
    - name: Check for outdated dependencies
      run: |
        echo "🔍 Checking for outdated dependencies..."
        cargo outdated --verbose > outdated_deps.txt 2>&1 || true
        
        if [ -s outdated_deps.txt ]; then
          echo "📋 Outdated dependencies found:"
          cat outdated_deps.txt
          echo "OUTDATED_DEPS=true" >> $GITHUB_ENV
        else
          echo "✅ All dependencies are up to date"
          echo "OUTDATED_DEPS=false" >> $GITHUB_ENV
        fi
    
    - name: Update dependencies
      if: env.OUTDATED_DEPS == 'true'
      run: |
        echo "📦 Updating dependencies..."
        
        # Update patch versions only (safer)
        cargo update
        
        # Check if updates work
        cargo check
        cargo test
    
    - name: Create Pull Request
      if: env.OUTDATED_DEPS == 'true'
      uses: peter-evans/create-pull-request@v5
      with:
        token: ${{ secrets.GITHUB_TOKEN }}
        commit-message: "chore: update dependencies"
        title: "🔄 Update dependencies"
        body: |
          ## 📦 Dependency Updates
          
          This PR updates project dependencies to their latest compatible versions.
          
          ### Changes
          - Updated Cargo.lock with latest patch versions
          - All tests pass with updated dependencies
          
          ### Verification
          - ✅ Project builds successfully
          - ✅ All tests pass
          - ✅ Security audit clean
          
          ### Outdated Dependencies Report
          ```
          $(cat outdated_deps.txt)
          ```
          
          **Auto-generated by maintenance workflow**
        branch: dependency-updates
        delete-branch: true

  security-audit:
    name: Security Audit
    if: github.event_name == 'schedule' || github.event.inputs.security_audit == 'true'
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    
    - name: Install Rust
      uses: dtolnay/rust-toolchain@stable
    
    - name: Install cargo-audit
      run: cargo install cargo-audit
    
    - name: Install cargo-deny
      run: cargo install cargo-deny
    
    - name: Run cargo-audit
      run: |
        echo "🔒 Running security audit..."
        cargo audit --json > audit_results.json 2>&1 || true
        
        # Check if vulnerabilities were found
        if jq -e '.vulnerabilities.found' audit_results.json > /dev/null 2>&1; then
          echo "⚠️ Security vulnerabilities found!"
          cargo audit
          echo "VULNERABILITIES_FOUND=true" >> $GITHUB_ENV
        else
          echo "✅ No security vulnerabilities found"
          echo "VULNERABILITIES_FOUND=false" >> $GITHUB_ENV
        fi
    
    - name: Run cargo-deny
      run: |
        echo "📋 Running license and dependency checks..."
        
        # Create deny.toml if it doesn't exist
        if [ ! -f deny.toml ]; then
          cat > deny.toml << 'EOF'
        [licenses]
        allow = ["MIT", "Apache-2.0", "ISC", "BSD-3-Clause", "Unicode-DFS-2016"]
        deny = ["GPL-3.0"]
        
        [bans]
        multiple-versions = "warn"
        wildcards = "allow"
        
        [advisories]
        vulnerability = "deny"
        unmaintained = "warn"
        yanked = "deny"
        EOF
        fi
        
        cargo deny check
    
    - name: Create security issue
      if: env.VULNERABILITIES_FOUND == 'true'
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          const auditResults = JSON.parse(fs.readFileSync('audit_results.json', 'utf8'));
          
          const title = '🚨 Security Vulnerabilities Detected';
          const body = `## Security Audit Report
          
          **Vulnerabilities found**: ${auditResults.vulnerabilities.found}
          
          ### Details
          ${JSON.stringify(auditResults.vulnerabilities.list, null, 2)}
          
          ### Action Required
          Please review and update the affected dependencies as soon as possible.
          
          ### Generated Report
          \`\`\`json
          ${JSON.stringify(auditResults, null, 2)}
          \`\`\`
          
          **Auto-generated by maintenance workflow**`;
          
          github.rest.issues.create({
            owner: context.repo.owner,
            repo: context.repo.repo,
            title: title,
            body: body,
            labels: ['security', 'high-priority']
          });

  performance-monitoring:
    name: Performance Monitoring
    if: github.event.inputs.performance_check == 'true'
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    
    - name: Install Rust
      uses: dtolnay/rust-toolchain@stable
    
    - name: Install hyperfine
      run: |
        wget https://github.com/sharkdp/hyperfine/releases/download/v1.16.1/hyperfine_1.16.1_amd64.deb
        sudo dpkg -i hyperfine_1.16.1_amd64.deb
    
    - name: Build release binary
      run: cargo build --release
    
    - name: Run performance benchmarks
      run: |
        echo "⚡ Running performance benchmarks..."
        mkdir -p benchmarks
        
        # Benchmark basic operations
        echo "📊 Basic operations benchmark:"
        hyperfine \
          --export-json benchmarks/basic_ops.json \
          --warmup 3 \
          --runs 10 \
          "./target/release/mage -c 'incant \"Hello World\"'" \
          "./target/release/mage -c 'conjure x = 42; incant x'" \
          "./target/release/mage -c 'chant i from 1 to 100 { conjure x = i }'"
        
        # Benchmark package operations
        echo "📦 Package operations benchmark:"
        mkdir -p bench_project
        cd bench_project
        hyperfine \
          --export-json ../benchmarks/package_ops.json \
          --warmup 1 \
          --runs 5 \
          "../target/release/mage -c 'cast package_init(\"bench-test\")'"
        cd ..
        
        # Benchmark file operations
        echo "📁 File operations benchmark:"
        hyperfine \
          --export-json benchmarks/file_ops.json \
          --warmup 2 \
          --runs 10 \
          "./target/release/mage -c 'cast write_file(\"test.txt\", \"Hello\")'" \
          "./target/release/mage -c 'cast file_exists(\"test.txt\")'"
        
        echo "✅ Performance benchmarks completed!"
    
    - name: Analyze performance results
      run: |
        echo "📈 Performance Analysis:"
        
        # Check if any operation is slower than expected thresholds
        python3 << 'EOF'
        import json
        import sys
        
        def analyze_benchmark(file_path, threshold_ms):
            try:
                with open(file_path, 'r') as f:
                    data = json.load(f)
                
                print(f"\n📊 Analysis for {file_path}:")
                for result in data['results']:
                    command = result['command']
                    mean_time = result['mean'] * 1000  # Convert to ms
                    
                    print(f"  {command}: {mean_time:.2f}ms")
                    
                    if mean_time > threshold_ms:
                        print(f"  ⚠️  Performance issue: {mean_time:.2f}ms > {threshold_ms}ms threshold")
                        return False
                    else:
                        print(f"  ✅ Performance OK: {mean_time:.2f}ms < {threshold_ms}ms threshold")
                
                return True
            except Exception as e:
                print(f"Error analyzing {file_path}: {e}")
                return True
        
        all_good = True
        all_good &= analyze_benchmark('benchmarks/basic_ops.json', 100)  # 100ms threshold
        all_good &= analyze_benchmark('benchmarks/package_ops.json', 2000)  # 2s threshold
        all_good &= analyze_benchmark('benchmarks/file_ops.json', 50)  # 50ms threshold
        
        if not all_good:
            print("\n❌ Performance regression detected!")
            sys.exit(1)
        else:
            print("\n✅ All performance benchmarks passed!")
        EOF
    
    - name: Upload benchmark results
      uses: actions/upload-artifact@v4
      with:
        name: performance-benchmarks
        path: benchmarks/

  code-quality-checks:
    name: Code Quality Checks
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    
    - name: Install Rust
      uses: dtolnay/rust-toolchain@stable
      with:
        components: rustfmt, clippy
    
    - name: Install additional tools
      run: |
        cargo install cargo-bloat
        cargo install tokei
    
    - name: Check code formatting
      run: |
        echo "🎨 Checking code formatting..."
        cargo fmt --all -- --check
    
    - name: Run Clippy with extra lints
      run: |
        echo "📎 Running Clippy with extra lints..."
        cargo clippy --all-targets --all-features -- \
          -D warnings \
          -D clippy::pedantic \
          -D clippy::nursery \
          -A clippy::missing_errors_doc \
          -A clippy::missing_panics_doc
    
    - name: Check binary size
      run: |
        echo "📏 Checking binary size..."
        cargo build --release
        
        # Get binary size
        BINARY_SIZE=$(stat -c%s target/release/mage)
        BINARY_SIZE_MB=$((BINARY_SIZE / 1024 / 1024))
        
        echo "Binary size: ${BINARY_SIZE_MB}MB (${BINARY_SIZE} bytes)"
        
        # Check for binary bloat
        cargo bloat --release --crates
        
        # Warn if binary is too large (>50MB)
        if [ $BINARY_SIZE_MB -gt 50 ]; then
          echo "⚠️ Binary size is quite large: ${BINARY_SIZE_MB}MB"
          echo "Consider optimizing dependencies or enabling more aggressive optimizations"
        else
          echo "✅ Binary size is reasonable: ${BINARY_SIZE_MB}MB"
        fi
    
    - name: Count lines of code
      run: |
        echo "📊 Code statistics:"
        tokei
    
    - name: Check for TODO/FIXME comments
      run: |
        echo "📝 Checking for TODO/FIXME comments..."
        
        TODO_COUNT=$(grep -r "TODO\|FIXME" src/ || true | wc -l)
        
        if [ $TODO_COUNT -gt 0 ]; then
          echo "Found $TODO_COUNT TODO/FIXME comments:"
          grep -rn "TODO\|FIXME" src/ || true
          
          if [ $TODO_COUNT -gt 20 ]; then
            echo "⚠️ High number of TODO/FIXME comments ($TODO_COUNT)"
            echo "Consider addressing some of these technical debt items"
          fi
        else
          echo "✅ No TODO/FIXME comments found"
        fi

  create-maintenance-summary:
    name: Create Maintenance Summary
    needs: [dependency-updates, security-audit, code-quality-checks]
    if: always()
    runs-on: ubuntu-latest
    steps:
    - uses: actions/checkout@v4
    
    - name: Create maintenance summary
      uses: actions/github-script@v7
      with:
        script: |
          const { context } = require('@actions/github');
          
          // Get job results
          const jobs = [
            { name: 'dependency-updates', result: '${{ needs.dependency-updates.result }}' },
            { name: 'security-audit', result: '${{ needs.security-audit.result }}' },
            { name: 'code-quality-checks', result: '${{ needs.code-quality-checks.result }}' }
          ];
          
          let summary = `## 🔧 Maintenance Summary - ${new Date().toISOString().split('T')[0]}\n\n`;
          
          // Job status summary
          summary += `### Job Results\n`;
          for (const job of jobs) {
            const icon = job.result === 'success' ? '✅' : 
                        job.result === 'failure' ? '❌' : 
                        job.result === 'skipped' ? '⏭️' : '⚠️';
            summary += `- ${icon} **${job.name}**: ${job.result}\n`;
          }
          
          summary += `\n### Next Steps\n`;
          
          if (jobs.some(j => j.result === 'failure')) {
            summary += `- 🔴 **Action Required**: Some maintenance checks failed\n`;
            summary += `- Review failed jobs and address issues\n`;
          } else {
            summary += `- ✅ **All Good**: All maintenance checks passed\n`;
            summary += `- No immediate action required\n`;
          }
          
          summary += `\n### Maintenance Schedule\n`;
          summary += `- Dependencies: Weekly (Mondays)\n`;
          summary += `- Security audits: Weekly (Mondays)\n`;
          summary += `- Performance checks: On-demand\n`;
          
          summary += `\n---\n*Auto-generated maintenance summary*`;
          
          // Create or update maintenance issue
          const issues = await github.rest.issues.listForRepo({
            owner: context.repo.owner,
            repo: context.repo.repo,
            labels: 'maintenance',
            state: 'open'
          });
          
          const title = `🔧 Weekly Maintenance Summary`;
          
          if (issues.data.length > 0) {
            // Update existing issue
            await github.rest.issues.update({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: issues.data[0].number,
              body: summary
            });
          } else {
            // Create new issue
            await github.rest.issues.create({
              owner: context.repo.owner,
              repo: context.repo.repo,
              title: title,
              body: summary,
              labels: ['maintenance']
            });
          } 